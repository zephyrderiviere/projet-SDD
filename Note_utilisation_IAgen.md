# Note sur l’utilisation d’outils d’IA générative 

La tentation de s'aider d'agents conversationnels ou d'assistants de code qui s'appuient sur l'IA générative (tels que ChatGPT, Claude, LeChat, ou Copilot) pour réaliser un projet numérique peut être grande. Néanmoins, cette utilisation entrave l'apprentissage, notamment car en fournissant directement une solution (possiblement erronée par ailleurs), elle ne permet pas de mener le cheminement mental nécessaire à l'acquisition de nouvelles compétences. 

Plusieurs études montrent l'effet délétère de l'utilisation de ces béquilles sur l'apprentissage (Bastani et al., 2024), sur les capacités cognitives des étudiantes et étudiants qui les utilisent de manière suffisamment peu critique (Zhai et al., 2024), ou encore sur la qualité du code écrit par des développeuses et développeurs (Perry et al., 2023).  


⚠️ __L'utilisation d'agents conversationnels ou d'assistants de code est en conséquence prohibée pour la réalisation du mini-projet et sera sanctionnée.__ ⚠️


Notons aussi que l'utilisation de ces outils soulève de nombreux problèmes éthiques, écologiques et géopolitiques qui sont abordés dans le Chapitre 6 (Bonnes pratiques) du cours.  


### Références bibliographiques 

- H. Bastani, O. Bastani, A. Sungu, H. Ge, Ö Kabakcı, and R. Mariman (2024). Generative AI Can Harm Learning. The Wharton School Research Paper. http://dx.doi.org/10.2139/ssrn.4895486  
- N. Perry, M. Srivastava, D. Kumar, and D. Boneh (2023). Do Users Write More Insecure Code with AI Assistants? In Proceedings of the 2023 ACM SIGSAC Conference on Computer and Communications Security (CCS '23) 2785–2799. https://doi.org/10.1145/3576915.3623157 
- C. Zhai, S. Wibowo and L.D. Li (2024). The effects of over-reliance on AI dialogue systems on students' cognitive abilities: a systematic review. Smart Learn. Environ. 11, 28. https://doi.org/10.1186/s40561-024-00316-7 

 